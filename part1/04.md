# Encoding and Evolution

Changes in applications
- schema changes 
- ‚û°Ô∏è ***code changes***

How to deal with?
- schema changes: Database `schema-on-write` vs. `schema-on-read`
- `compatibility`: old and new versions of code, old and new data formats coexist at the same time
    - codes cannot change at once becuase
        - rolling upgrade
        - client may not update
    - which code reads data??
    - `backward compatibility`: *newer* code reads data written by *older* code
    - `forward compatibility`: *older* code reads data written by *newer* code
        - tricky: older code should ignore additions made by a newer version of code

Topics
1. formats for encoding data
    - how they handle schema changes
    - how they support compatibility
2. how those formats are used for data storage and web communications

## 1. Formats for Encoding Data

`encoding` & `decoding`
- data in 2 different representations
    1. in-memory representation
        - when?: data in memory
        - data is kept in objects, structs, lists, arrays, hash tables, trees, etc.
        - optimized for efficient access and manipulation by the CPU (typically using *pointers*)
    2. byte sequence
        - when?: write data to a file / send over the network
        - self-contained
        - no pointer ‚û°Ô∏è different from in-memory
- `encoding`: translation from *in-memory* representation to a byte sequence
- `decoding`: the reverse

### 1) Language-Specific Formats
Not recommended

üëç
- allow in-memory objects to be saved and restored with minimal additional code

üëé
- ‚≠êÔ∏è tied to a particualar programming language
- ‚≠êÔ∏è neglect versioning ‚û°Ô∏è tough compatibility
- security issue
    - decoding process needs to instantiate arbitrary classes
    - decode an arbitrary byte sequence ‚û°Ô∏è instantiate arbitrary class
- neglect efficiency
    - CPU time taken to encode or decode
    - size of the enocded structure

### 2) JSON, XML, and Binary Variants: Schemaless
standardized encodings

`Textual Formats` 
- human-readable
- remain popular
    - JSON, XML, CSV
- problems: schema üò£
    - ambiguity around the encoding of numbers
        - XML, CSV: not distinguish between a number and a string consisting of digits
        - JSON: not distinguish integers and floating-point numbers (large number 2^53 üò±)
    - JSON, XML: don't support binary strings
        - binary string: sequence of bytes without a character encoding
        - workaround: tricky and increase data size
    - Weak schema support
        - JSON, XML: complicated
        - CSV: No schema

`Binary Encoding` variant
- for JSON, XML
- not widely adopted
- üëç: extend the set of datatypes
- ü§î: *small space reduction*
    - No prescribed schema ‚û°Ô∏è include *all* field names
    - Íµ≥Ïù¥...?

### 3) Thrift and Protocol Buffers: Schema
`Binary Encoding` libraries

characteristics 
- require `schema`
    - code generation tool: takes schema definition and prodcues class implementing the schema
    - required fields: runtime check
- encoded record: concatenation of its encoded fields
    - each field identified by *tag number*

Types
1. Thrift: Binary Protocol
    - Facebook
    - no field name: ***field tags***
2. Thrift: Compact Protocol
    - more compact
        - packing the field type and field tag into a single byte
        - use variable-length integers
3. Protocol Buffers
    - Google
    - mostly similar to compact protocol

schema evolution
1. CANNOT CHANGE a field's tag
2. adding a new field
    - `backward`: new field should be either OPTIONAL or have a DEFAULT VALUE
    - `forward`: older code ignore new fields
3. removing a field: required field can never be removed
    - `backward`: ignore old field
    - `forward`: removed field is OPTIONAL and tag number never to be reused
4. Datatypes
    - risky: Check if they are convertible
        - ex) 32-bit int in old code vs. 64-bit int in new code ‚û°Ô∏è tuncation
    - list of values
        - Protocol Buffers: No list or array datatype: `repeated` 
            - OPTIONAL datatypes ‚ÜîÔ∏è repeated types
        - Thrift: List datatype
            - No evolution
            - but support nested lists

### 4) Avro: Schema
characteristics
- Subproject of Hadoop
- use schema: `reader's schema` & `writer's schema`
    - `reader's schema`: used in decoding
    - `writer's schema`: used in encoding
        - large file with lots of records
            - included at the beginning of the file
        - Database with individually written records
            - include a version number at the beginning of every encoded record
            - keep a list of schema versions in database
            - ex) Espresso
        - Sending records over a network connection
            - negotiate the schema version on connection setup and then use that schema for the lifetime of the connection
- no `required/optional`: `union` & default
- encoded record: values concatenated together (no datatypes or field tags) ‚û°Ô∏è the most compact
    - use variable-length integers

Schema evolution
- achieved by schema resolution: compare the writer's schema and reader's schema side by side and translate the data from the former to the latter
1. add or remove a field with default values (= Thrift & Protocol Buffers)
    - `null` should be included in `union` branches (as the first if it is the default value)
2. changing the datatypes
    - if convertible: OK
    - adding a branch to a union: backward O / forward X
3. changing the name of a field: backward O / forward X

Advantages
- no tag number ‚û°Ô∏è friendlier to dynamically generated schemas
    - ex) Using a RDB
        - schema changes: generate a new Avro schema from the updated DB schema and export data in the new Avro schema
        - Thrift and Protobuf: the field tags have to be assigne by hand
- code generation and dynamically type languages
    - 

### 5) The Merits of Schema
merits of schema
1. more compact
2. easier and more valuable documenation
    - schema is required for decoding ‚û°Ô∏è sure it is up to date
3. easier to check forward and backward compatibility of schema changes
4. Statically typed programming languages: 

schema evolution ‚û°Ô∏è
  - flexibility like schemaless JSON databases
  - `+` better guarantees about your data 
  - `+` better tooling

## 2. Modes of Dataflow

How data flow from from one process to another?
1. Via databases
2. Via service calls
3. Via asynchronos message passing

### 1) Dataflow Through Databases

### 2) Dataflow Through Serivces: REST and RPC
### 3) Message-Passing Dataflow
